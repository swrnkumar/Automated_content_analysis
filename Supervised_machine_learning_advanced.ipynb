{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised machine learning with text\n",
    "### The case of having access to a large newspaper dataset with annotated topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started out with having a folder with all the newspaper articles (in .txt files) that were annotated. Additionally, I had a file called np_workfile.csv that included a lot of infromation about the articles and -- most importantly -- the topic annotations. Starting from this, I first had to process the text in all the article files and get it together with the annotation file. This is the code I used (with explanations on the side): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import maxunicode #library to get everything that might be punctuation\n",
    "import unicodedata #library to get everything that might be punctuation\n",
    "from nltk.corpus import stopwords #stopword list\n",
    "from nltk.tokenize import word_tokenize #tokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer #stemmer\n",
    "import nltk #also including the overall model since later on other submodules are addressed\n",
    "\n",
    "np_data = pd.read_csv('/home/felicia/News_classifier/np_workfile.csv') #reading the file with the annotations\n",
    "tbl = dict.fromkeys(i for i in range(maxunicode) if unicodedata.category(chr(i)).startswith('P')) #list of all punctuation\n",
    "stopwords_list = set(stopwords.words('dutch')) #list of all Dutch stopwords\n",
    "stemmer=SnowballStemmer('dutch') #initializing Dutch stemmer\n",
    "\n",
    "#since the name of the full text to the newspaper articles was a column in the CSV file\n",
    "#I had to write a function that points to the folder where I saved the articles and adds the filename to it\n",
    "#\n",
    "def substitute_location(text):\n",
    "    text_new = '/home/felicia/News_classifier/articles/' + text \n",
    "    return text_new\n",
    "\n",
    "np_data['Filename']=np_data['V3'].apply(substitute_location) #Making a new column called filename with the full path\n",
    "\n",
    "'''\n",
    "Defining a function that: \n",
    "- opens every file\n",
    "- reads it and splits it, filters empty lines out\n",
    "- Since those are LexisNexis files, I made two general rules to find the beginning and end of the main text\n",
    "- retrieving the main text between beginning and end, joining together the separate lines to have one string and not a list\n",
    "- removing weird characters and punctuation\n",
    "- tokenizing the text\n",
    "- stemming and lowercasing the text\n",
    "- making bigrams\n",
    "- joining unigrams and bigrams to one processed text\n",
    "'''\n",
    "def process_text(filename):\n",
    "    with open(filename) as fi:\n",
    "        text = fi.read().splitlines()\n",
    "        text = list(filter(None,text))\n",
    "        beginning = [i for i, s in enumerate(text) if 'LENGTH' in s or 'DATELINE' in s or 'LENGTE' in s]\n",
    "        end = [i for i, s in enumerate(text) if 'LOAD-DATE' in s or 'LANGUAGE' in s]\n",
    "        text = text[beginning[-1]+1:end[0]]\n",
    "        text = ''.join(text)\n",
    "        text = text.replace(u\"`\",u\"\").replace(u\"Â´\",u\"\").translate(tbl)\n",
    "        text = word_tokenize(text)\n",
    "        text = [stemmer.stem(w.lower()) for w in text if w.lower() not in stopwords_list and not (w.isalpha() and len(w)==1)]\n",
    "        text_bigrams = [\"_\".join(tup) for tup in nltk.ngrams(text,2)]\n",
    "        text_final = text + text_bigrams\n",
    "        return text_final\n",
    "\n",
    "#Applying the above function to the dataframe, makimg a new column with the processed text in it\n",
    "#Saving the resulting file as pkl file\n",
    "np_data['Processed_text']=np_data['Filename'].apply(process_text)\n",
    "np_data.to_pickle(\"/home/felicia/News_classifier/classifier_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./classifier_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dataframe, the most important columns are \"Processed_text\" and v9_major_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hits</th>\n",
       "      <th>Score</th>\n",
       "      <th>ScorePercent</th>\n",
       "      <th>Filename</th>\n",
       "      <th>V3</th>\n",
       "      <th>Size</th>\n",
       "      <th>WordCt</th>\n",
       "      <th>Title</th>\n",
       "      <th>headline</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>filename2</th>\n",
       "      <th>v9_major</th>\n",
       "      <th>dubbel</th>\n",
       "      <th>in</th>\n",
       "      <th>Processed_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>v9_major_rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/home/felicia/News_classifier/articles/#100 @3...</td>\n",
       "      <td>#100 @328419 +2073</td>\n",
       "      <td>2073</td>\n",
       "      <td>318</td>\n",
       "      <td>1899 of 1983 DOCUMENTS NRC Handelsblad January...</td>\n",
       "      <td>1899 of 1983 DOCUMENTS;;;; January 16, 1999;;;...</td>\n",
       "      <td>LENGTH: 285 words</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[wereld, zondagmorg, antropolog, dr, mattijs, ...</td>\n",
       "      <td>Anders/ diversen</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>/home/felicia/News_classifier/articles/#10000 ...</td>\n",
       "      <td>#10000 @16311398 +11159</td>\n",
       "      <td>11159</td>\n",
       "      <td>1775</td>\n",
       "      <td>171 of 2386 DOCUMENTS De Telegraaf 6 december ...</td>\n",
       "      <td>171 of 2386 DOCUMENTS;;;; De Telegraaf;; 6 dec...</td>\n",
       "      <td>LENGTH: 1693 woorden</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[samenvattingd, speurtocht, efraim, zuroff, na...</td>\n",
       "      <td>Defensie</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>/home/felicia/News_classifier/articles/#10004 ...</td>\n",
       "      <td>#10004 @16327565 +1346</td>\n",
       "      <td>1346</td>\n",
       "      <td>185</td>\n",
       "      <td>175 of 2386 DOCUMENTS De Telegraaf 5 december ...</td>\n",
       "      <td>175 of 2386 DOCUMENTS;;;;;;;;;;;;</td>\n",
       "      <td>LENGTH: 141 woorden</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[vol, verwacht, klopp, hartjes, onz, stoer, ma...</td>\n",
       "      <td>Defensie</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>/home/felicia/News_classifier/articles/#10004 ...</td>\n",
       "      <td>#10004 @34719038 +2546</td>\n",
       "      <td>2546</td>\n",
       "      <td>368</td>\n",
       "      <td>1142 of 1781 DOCUMENTS de Volkskrant May 1, 20...</td>\n",
       "      <td>1142 of 1781 DOCUMENTS;;;; May 1, 2001;; Werkg...</td>\n",
       "      <td>LENGTH: 349 words</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[nieuwkomer, bedrijf, denkt, flink, salaris, g...</td>\n",
       "      <td>Arbeid</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/home/felicia/News_classifier/articles/#10005 ...</td>\n",
       "      <td>#10005 @37431676 +6256</td>\n",
       "      <td>6256</td>\n",
       "      <td>989</td>\n",
       "      <td>1189 of 1778 DOCUMENTS NRC Handelsblad May 7, ...</td>\n",
       "      <td>1189 of 1778 DOCUMENTS;;;; May 7, 2001;; 'Tijd...</td>\n",
       "      <td>LENGTH: 955 words</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ziekenhuiz, hengelo, leeuward, vandag, gestaa...</td>\n",
       "      <td>Gezondheid</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hits Score ScorePercent                                           Filename  \\\n",
       "0    1     1           11  /home/felicia/News_classifier/articles/#100 @3...   \n",
       "1    3     3           20  /home/felicia/News_classifier/articles/#10000 ...   \n",
       "2    3     3           20  /home/felicia/News_classifier/articles/#10004 ...   \n",
       "3    1     1           12  /home/felicia/News_classifier/articles/#10004 ...   \n",
       "4    1     1           11  /home/felicia/News_classifier/articles/#10005 ...   \n",
       "\n",
       "                        V3   Size WordCt  \\\n",
       "0       #100 @328419 +2073   2073    318   \n",
       "1  #10000 @16311398 +11159  11159   1775   \n",
       "2   #10004 @16327565 +1346   1346    185   \n",
       "3   #10004 @34719038 +2546   2546    368   \n",
       "4   #10005 @37431676 +6256   6256    989   \n",
       "\n",
       "                                               Title  \\\n",
       "0  1899 of 1983 DOCUMENTS NRC Handelsblad January...   \n",
       "1  171 of 2386 DOCUMENTS De Telegraaf 6 december ...   \n",
       "2  175 of 2386 DOCUMENTS De Telegraaf 5 december ...   \n",
       "3  1142 of 1781 DOCUMENTS de Volkskrant May 1, 20...   \n",
       "4  1189 of 1778 DOCUMENTS NRC Handelsblad May 7, ...   \n",
       "\n",
       "                                            headline                length  \\\n",
       "0  1899 of 1983 DOCUMENTS;;;; January 16, 1999;;;...     LENGTH: 285 words   \n",
       "1  171 of 2386 DOCUMENTS;;;; De Telegraaf;; 6 dec...  LENGTH: 1693 woorden   \n",
       "2                  175 of 2386 DOCUMENTS;;;;;;;;;;;;   LENGTH: 141 woorden   \n",
       "3  1142 of 1781 DOCUMENTS;;;; May 1, 2001;; Werkg...     LENGTH: 349 words   \n",
       "4  1189 of 1778 DOCUMENTS;;;; May 7, 2001;; 'Tijd...     LENGTH: 955 words   \n",
       "\n",
       "   ... V42 V43 V44 filename2 v9_major dubbel in  \\\n",
       "0  ...                     0       99      0  1   \n",
       "1  ...   1   2   2         0       16      0  1   \n",
       "2  ...                     0       16      0  1   \n",
       "3  ...                     0        5      0  1   \n",
       "4  ...                     0        3      0  1   \n",
       "\n",
       "                                      Processed_text             topic  \\\n",
       "0  [wereld, zondagmorg, antropolog, dr, mattijs, ...  Anders/ diversen   \n",
       "1  [samenvattingd, speurtocht, efraim, zuroff, na...          Defensie   \n",
       "2  [vol, verwacht, klopp, hartjes, onz, stoer, ma...          Defensie   \n",
       "3  [nieuwkomer, bedrijf, denkt, flink, salaris, g...            Arbeid   \n",
       "4  [ziekenhuiz, hengelo, leeuward, vandag, gestaa...        Gezondheid   \n",
       "\n",
       "  v9_major_rec  \n",
       "0           99  \n",
       "1           16  \n",
       "2           16  \n",
       "3            5  \n",
       "4            3  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.v9_major_rec != \" \"] #filtering out rows with empty topic variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11124"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) #total number of annotated articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I was not interested in very finegrained, small topics but rather 9-10 larger ones \n",
    "#I recoded the topic variable by using a dictionary and my own function\n",
    "recode = {'Binnenland':['13','14','20', '3', '4', '5', '6'], 'Buitenland':['16', '19', '2'], 'Economie':['1','15'], 'Milieu':['8', '7'],  'Wetenschap':['17'], 'Immigratie':['9'],  'Justitie':['12'], 'Sport':['29'], 'Entertainment':['23'], 'Anders':['10','99']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_topics(number):\n",
    "    for key, value in recode.items():\n",
    "        if number in value:\n",
    "            result = key\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df['v9_major_rec'].apply(recode_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binnenland       2500\n",
       "Buitenland       1831\n",
       "Anders           1670\n",
       "Justitie         1201\n",
       "Entertainment    1043\n",
       "Economie         1036\n",
       "Sport            1029\n",
       "Wetenschap        427\n",
       "Milieu            235\n",
       "Immigratie        152\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].value_counts() #amount of different topics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.topic #making a separate variable out of the topic column\n",
    "df = df.drop('topic', axis = 1) #dropping the topic column from the dataset (since it cannot be part of the test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_text']=[\" \".join(text) for text in df['Processed_text'].values] #processed text was in a list, now I again need it as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Processed_text'], y, test_size=0.2) #doing a test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() #initializing a vectorizer\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) #training the vectorizer\n",
    "with open('vectorizer.pkl', 'wb') as fin: #saving the vectorizer (in case I need it later again and do not want to retrain it)\n",
    "    joblib.dump(tfidf_vectorizer, fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(X_test) #transforming the test data with the same vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_clf = PassiveAggressiveClassifier(n_iter=50) #initializing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
       "              max_iter=None, n_iter=50, n_iter_no_change=5, n_jobs=None,\n",
       "              random_state=None, shuffle=True, tol=None,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_clf.fit(tfidf_train, y_train) #running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.691\n"
     ]
    }
   ],
   "source": [
    "pred = linear_clf.predict(tfidf_test) #predicting the scores\n",
    "score = metrics.accuracy_score(y_test, pred) #getting metrics to evaluate\n",
    "print(\"accuracy:   %0.3f\" % score) #overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra gimmick: making a classification report (only to make it look pretty and \n",
    "#get a nice overview, not necessary for the analysis)\n",
    "a = classification_report(y_test, pred, target_names = ['Binnenland', 'Buitenland', 'Economie', 'Milieu', 'Wetenschap', 'Justitie', 'Immigratie', 'Sport', 'Entertainment', 'Anders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def classification_report_pandas(ground_truth,\n",
    "                                            predictions):\n",
    "    \"\"\"\n",
    "    Saves the classification report to csv using the pandas module.\n",
    "    :param ground_truth: list: the true labels\n",
    "    :param predictions: list: the predicted labels\n",
    "    \"\"\"\n",
    "    labels = unique_labels(ground_truth, predictions)\n",
    "\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(ground_truth,\n",
    "                                                                          predictions,\n",
    "                                                                          labels=labels,\n",
    "                                                                          average=None)\n",
    "    results_pd = pd.DataFrame({\"topic\": labels,\n",
    "                               \"f_score\": f_score,\n",
    "                               'precision': precision,\n",
    "                               'recall':recall,\n",
    "                               })\n",
    "    return results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = classification_report_pandas(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['index'] = b.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(df2, b, left_on='topic', right_on='index')\n",
    "final = final.drop('index', axis = 1)\n",
    "final.rename(columns = {'topic_y':'number', 'topic_x':'topic'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anders</td>\n",
       "      <td>0.643857</td>\n",
       "      <td>0.685430</td>\n",
       "      <td>0.607038</td>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Binnenland</td>\n",
       "      <td>0.679962</td>\n",
       "      <td>0.640429</td>\n",
       "      <td>0.724696</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buitenland</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.663462</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economie</td>\n",
       "      <td>0.693976</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.675127</td>\n",
       "      <td>0.711230</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Immigratie</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Justitie</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.681223</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Milieu</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sport</td>\n",
       "      <td>0.895787</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wetenschap</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic   f_score  precision    recall  number\n",
       "0         Anders  0.643857   0.685430  0.607038    1670\n",
       "1     Binnenland  0.679962   0.640429  0.724696    2500\n",
       "2     Buitenland  0.696970   0.663462  0.734043    1831\n",
       "3       Economie  0.693976   0.727273  0.663594    1036\n",
       "4  Entertainment  0.692708   0.675127  0.711230    1043\n",
       "5     Immigratie  0.521739   0.750000  0.400000     152\n",
       "6       Justitie  0.688742   0.696429  0.681223    1201\n",
       "7         Milieu  0.412698   0.764706  0.282609     235\n",
       "8          Sport  0.895787   0.893805  0.897778    1029\n",
       "9     Wetenschap  0.493333   0.528571  0.462500     427"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final #printing the evaluation metrics for each topic and how often it appeared in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topic_classifier.pkl', 'wb') as fid: #saving the classifier in a file (so I do not have to retrain it again)\n",
    "    joblib.dump(linear_clf, fid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
